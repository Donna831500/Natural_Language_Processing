{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  tag  count\n",
       "0      1  Pierre  NNP      6\n",
       "1      1  Pierre  NNP      6\n",
       "2      9  Pierre  NNP      6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "train = pd.read_table('train',header=None, names=['index','word','tag'])\n",
    "# count the occurence of each word\n",
    "train_word_count = train.groupby('word').size().reset_index(name='count')\n",
    "# add occurence of each word as a new column to filter out '<unk>'\n",
    "train_df = pd.merge(train, train_word_count, on='word') \n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>count</th>\n",
       "      <th>filterd_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "      <td>Pierre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "      <td>Pierre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "      <td>Pierre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  tag  count filterd_word\n",
       "0      1  Pierre  NNP      6       Pierre\n",
       "1      1  Pierre  NNP      6       Pierre\n",
       "2      9  Pierre  NNP      6       Pierre"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set threshold and filter out '<unk>', the new word column is 'filterd_word'\n",
    "threshold = 2\n",
    "def label_unk(row):\n",
    "    if row['count']<threshold:\n",
    "        return '<unk>';\n",
    "    else:\n",
    "        return row['word'];\n",
    "    \n",
    "train_df['filterd_word'] = train_df.apply (lambda row: label_unk(row), axis=1)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filterd_word</th>\n",
       "      <th>occurance</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>20011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>39533</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filterd_word  occurance  index\n",
       "0        <unk>      20011      1\n",
       "1            ,      46476      2\n",
       "2          the      39533      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Task1 output ####\n",
    "\n",
    "# count the occurence of each filtered word\n",
    "task1_output = train_df.groupby('filterd_word').size().reset_index(name='occurance')\n",
    "# sort dataframe based on occurence of each word\n",
    "task1_output = task1_output.sort_values(by='occurance', ascending=False)\n",
    "\n",
    "# let word '<unk>' on the first row of dataframe\n",
    "task1_output = task1_output.reset_index(drop=True)\n",
    "unk_index = task1_output.index[task1_output['filterd_word'] == '<unk>'].tolist()\n",
    "unk_index = unk_index[0]\n",
    "task1_output[\"new\"] = range(1,len(task1_output)+1)\n",
    "task1_output.loc[task1_output.index==unk_index, 'new'] = 0\n",
    "task1_output = task1_output.sort_values(\"new\").drop('new', axis=1)\n",
    "task1_output = task1_output.reset_index(drop=True)\n",
    "\n",
    "# add index to the dataframe\n",
    "task1_output[\"index\"] = range(1,len(task1_output)+1)\n",
    "task1_output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold I selected for unknown words replacement is 2\n",
      "The number of vocabulary is 23183\n",
      "The total size of vocabulary is 912095\n",
      "The occurence of \"<unk>\" is 20011\n"
     ]
    }
   ],
   "source": [
    "print('The threshold I selected for unknown words replacement is '+str(threshold))\n",
    "print('The number of vocabulary is '+str(task1_output.iloc[:,0].size))\n",
    "print('The total size of vocabulary is '+str(task1_output['occurance'].sum()))\n",
    "print('The occurence of \"<unk>\" is '+str(task1_output.at[0,'occurance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to vocab.txt\n",
    "task1_output_list = task1_output.values.tolist()\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    for each_output in task1_output_list:\n",
    "        word_type = each_output[0]\n",
    "        occurence = each_output[1]\n",
    "        index = each_output[2]\n",
    "        f.write(word_type+'\\t'+str(index)+'\\t'+str(occurence))\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split '<unk>' to two categories to improve accuracy\n",
    "def label_unk(row):\n",
    "    if row['count']<threshold:\n",
    "        # if the word start with digit, then it is '<unk_digit>' word\n",
    "        if row['word'][0]>= '0' and row['word'] <= '9':\n",
    "            return '<unk_digit>';\n",
    "        # if the word does not start with digit, then it is regular'<unk>' word\n",
    "        else:\n",
    "            return '<unk>';\n",
    "    else:\n",
    "        return row['word'];\n",
    "    \n",
    "train_df['filterd_word'] = train_df.apply (lambda row: label_unk(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a list of words for future computation\n",
    "all_word = task1_output['filterd_word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I split \"<unk>\" to two categories, which is \"<unk>\" and \"<unk_digit>\" to improve accuracy, \n",
      "The answers below are based on the data that after my preprocessed:\n",
      "The number of vocabulary is 23183\n",
      "The total size of vocabulary is 912095\n",
      "The occurence of \"<unk>\" is 17000\n"
     ]
    }
   ],
   "source": [
    "report_unk = train_df.groupby('filterd_word').size().reset_index(name='occurance')\n",
    "report_unk = report_unk[report_unk['filterd_word']=='<unk>'].reset_index(drop=True)\n",
    "\n",
    "print('I split \"<unk>\" to two categories, which is \"<unk>\" and \"<unk_digit>\" to improve accuracy, ')\n",
    "print('The answers below are based on the data that after my preprocessed:')\n",
    "\n",
    "print('The number of vocabulary is '+str(len(all_word)))\n",
    "print('The total size of vocabulary is '+str(task1_output['occurance'].sum()))\n",
    "print('The occurence of \"<unk>\" is '+str(report_unk.at[0,'occurance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  tag tag2\n",
       "0      1  Pierre  NNP  NNP\n",
       "1      2  Vinken  NNP    ,\n",
       "2      3       ,    ,   CD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add tag2 to dataframe in order to create transition tag pair\n",
    "# tag2 is the one row shift of original tag, which can represent next tag\n",
    "train_tag = train.copy()\n",
    "train_tag['tag2']=train_tag['tag']\n",
    "train_tag['tag2'] = train_tag.tag2.shift(-1,fill_value=train_tag.at[0,'tag'])\n",
    "train_tag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(NNP, NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "      <td>(NNP, ,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>CD</td>\n",
       "      <td>(,, CD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  tag tag2    tag_pair\n",
       "0      1  Pierre  NNP  NNP  (NNP, NNP)\n",
       "1      2  Vinken  NNP    ,    (NNP, ,)\n",
       "2      3       ,    ,   CD     (,, CD)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine two tags into tuple to get representation of transition\n",
    "def add_tag_pair(row):\n",
    "    return (row['tag'],row['tag2']);\n",
    "    \n",
    "train_tag['tag_pair'] = train_tag.apply (lambda row: add_tag_pair(row), axis=1)\n",
    "train_tag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_pair</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(#, ,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(#, CD)</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>($, CD)</td>\n",
       "      <td>6882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag_pair  count\n",
       "0   (#, ,)      1\n",
       "1  (#, CD)    126\n",
       "2  ($, CD)   6882"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of occurence of each transition and save to an list for future computation\n",
    "train_tagPair_count = train_tag.groupby('tag_pair').size().reset_index(name='count')\n",
    "pair_list = train_tagPair_count.values.tolist()\n",
    "train_tagPair_count.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$</td>\n",
       "      <td>6937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>''</td>\n",
       "      <td>6622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag  count\n",
       "0   #    127\n",
       "1   $   6937\n",
       "2  ''   6622"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of occurence of each tag and save to an dictionary for future computation\n",
    "train_tag_count = train_tag.groupby('tag').size().reset_index(name='count')\n",
    "tag_count_dict = train_tag_count.set_index('tag').to_dict()['count']\n",
    "train_tag_count.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition dictionary\n",
    "transition = {}\n",
    "# for transition tag pair, get its occurence from previous dictionary\n",
    "# also get start tag's occurence from previous dictionary\n",
    "# calculate the transition value and add it to transition dictionary as value with tag pair as key\n",
    "for each_pair in pair_list:\n",
    "    tag_pair = each_pair[0]\n",
    "    tag_pair_count = each_pair[1]\n",
    "    first_tag = tag_pair[0]\n",
    "    tag_count = tag_count_dict[first_tag]\n",
    "    transition[tag_pair]=tag_pair_count/tag_count\n",
    "#transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-edcb314f947c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_word_tag['tag_word_pair'] = train_word_tag.apply (lambda row: add_tag_word_pair(row), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filterd_word</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag_word_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(NNP, Pierre)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(NNP, Pierre)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(NNP, Pierre)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filterd_word  tag  tag_word_pair\n",
       "0       Pierre  NNP  (NNP, Pierre)\n",
       "1       Pierre  NNP  (NNP, Pierre)\n",
       "2       Pierre  NNP  (NNP, Pierre)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create (tag,word) pair to compute emission\n",
    "train_word_tag = train_df[['filterd_word','tag']]\n",
    "def add_tag_word_pair(row):\n",
    "    return (row['tag'],row['filterd_word']);\n",
    "    \n",
    "train_word_tag['tag_word_pair'] = train_word_tag.apply (lambda row: add_tag_word_pair(row), axis=1)\n",
    "train_word_tag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_word_pair</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(#, #)</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>($, $)</td>\n",
       "      <td>6762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>($, &lt;unk&gt;)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag_word_pair  count\n",
       "0        (#, #)    127\n",
       "1        ($, $)   6762\n",
       "2    ($, <unk>)      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of occurence of each emission and save to an list for future computation\n",
    "train_tag_word_pair_count = train_word_tag.groupby('tag_word_pair').size().reset_index(name='count')\n",
    "pair_list = train_tag_word_pair_count.values.tolist()\n",
    "train_tag_word_pair_count.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute emission dictionary\n",
    "emission = {}\n",
    "# for emission (tag,word) pair, get its occurence from previous dictionary\n",
    "# also get start tag's occurence from previous dictionary\n",
    "# calculate the emission value and add it to emission dictionary as value with (tag,word) pair as key\n",
    "for each_pair in pair_list:\n",
    "    tag_pair = each_pair[0]\n",
    "    tag_pair_count = each_pair[1]\n",
    "    first_tag = tag_pair[0]\n",
    "    tag_count = tag_count_dict[first_tag]\n",
    "    emission[tag_pair]=tag_pair_count/tag_count\n",
    "#emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output json file \n",
    "import json\n",
    "# convert tuple key to string in order to output to json file\n",
    "keys_values = transition.items()\n",
    "transition_output = {str(key): value for key, value in keys_values}\n",
    "keys_values2 = emission.items()\n",
    "emission_output = {str(key): value for key, value in keys_values2}\n",
    "\n",
    "with open('hmm.json', 'w') as fp:\n",
    "    json.dump(transition_output, fp, indent=2)\n",
    "    json.dump(emission_output, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of transition is 1378\n",
      "The size of emission is 30309\n"
     ]
    }
   ],
   "source": [
    "print('The size of transition is '+str(len(transition)))\n",
    "print('The size of emission is '+str(len(emission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>correct_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Corporations</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          word correct_tag\n",
       "0      1           The          DT\n",
       "1      2       Arizona         NNP\n",
       "2      3  Corporations         NNP"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dev data\n",
    "dev = pd.read_table('dev',header=None, names=['index','word','correct_tag'])#,delim_whitespace=True,header=0\n",
    "dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dev data to list for future computation\n",
    "dev_test = dev[['index','word']]\n",
    "all_tags = list(tag_count_dict.keys())\n",
    "index_list = dev_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Greedy Algorithm ####\n",
    "previous_tag=\".\"\n",
    "result_tag_list = []\n",
    "# for each word, compute the argmax(transition*emission)\n",
    "for each_row in index_list:\n",
    "    current_word = each_row[1]\n",
    "    # For some special character, the tag is fixed, so we can skip the computation step to save time\n",
    "    if current_word=='?':\n",
    "        predict_tag='.'\n",
    "    elif current_word=='--' or current_word=='...':\n",
    "        predict_tag=':'\n",
    "    elif current_word==')' or current_word=='}':\n",
    "        predict_tag='-RRB-'\n",
    "    elif current_word=='(' or current_word=='{':\n",
    "        predict_tag='-LRB-'\n",
    "    elif current_word in ['.',',','$','``']:\n",
    "        predict_tag=current_word\n",
    "    else:\n",
    "        # if the word is not in word dictionary, we treat it as unknown\n",
    "        if current_word not in all_word:\n",
    "            # treat the word as '<unk_digit>' if the word start with a digit\n",
    "            if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "                current_word='<unk_digit>'\n",
    "            else:\n",
    "                current_word='<unk>'\n",
    "\n",
    "        # for each tag, compute the transmission*emission value and take the argmax as predicted tag\n",
    "        te_list = []\n",
    "        for each_tag in all_tags:\n",
    "            t_value = transition.get((previous_tag,each_tag),0)\n",
    "            e_value = emission.get((each_tag,current_word),0)\n",
    "            te_list.append(t_value*e_value)\n",
    "        max_index = te_list.index(max(te_list))\n",
    "        predict_tag = all_tags[max_index]\n",
    "        \n",
    "    # save predicted tag as input of next round computation\n",
    "    previous_tag = predict_tag\n",
    "    # save answer for current word\n",
    "    result_tag_list.append(predict_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of applying Greedy algorithm on dev data is 0.9362288264221966\n"
     ]
    }
   ],
   "source": [
    "# add predicted tag as a new column to compute accuracy\n",
    "dev['greedy_tag']=result_tag_list\n",
    "num_correct = dev[dev['correct_tag']==dev['greedy_tag']].iloc[:,0].size\n",
    "print('The accuracy of applying Greedy algorithm on dev data is '+str(num_correct/dev.iloc[:,0].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting tags for test data\n",
    "# load test data\n",
    "test = pd.read_table('test',header=None, names=['index','word'])\n",
    "index_list_test = test.values.tolist()\n",
    "\n",
    "# Apply Greedy Algorithm to test data\n",
    "previous_tag=\".\"\n",
    "result_tag_list = []\n",
    "# for each word, compute the argmax(transition*emission)\n",
    "for each_row in index_list_test:\n",
    "    current_word = each_row[1]\n",
    "    # For some special character, the tag is fixed, so we can skip the computation step to save time\n",
    "    if current_word=='?':\n",
    "        predict_tag='.'\n",
    "    elif current_word=='--' or current_word=='...':\n",
    "        predict_tag=':'\n",
    "    elif current_word==')' or current_word=='}':\n",
    "        predict_tag='-RRB-'\n",
    "    elif current_word=='(' or current_word=='{':\n",
    "        predict_tag='-LRB-'\n",
    "    elif current_word in ['.',',','$','``']:\n",
    "        predict_tag=current_word\n",
    "    else:\n",
    "        # if the word is not in word dictionary, we treat it as unknown\n",
    "        if current_word not in all_word:\n",
    "            # treat the word as '<unk_digit>' if the word start with a digit\n",
    "            if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "                current_word='<unk_digit>'\n",
    "            else:\n",
    "                current_word='<unk>'\n",
    "\n",
    "        # for each tag, compute the transmission*emission value and take the argmax as predicted tag\n",
    "        te_list = []\n",
    "        for each_tag in all_tags:\n",
    "            t_value = transition.get((previous_tag,each_tag),0)\n",
    "            e_value = emission.get((each_tag,current_word),0)\n",
    "            te_list.append(t_value*e_value)\n",
    "        max_index = te_list.index(max(te_list))\n",
    "        predict_tag = all_tags[max_index]\n",
    "        \n",
    "    # save predicted tag as input of next round computation\n",
    "    previous_tag = predict_tag\n",
    "    # save answer for current word\n",
    "    result_tag_list.append(predict_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted tag as a new column and output it\n",
    "test['greedy_tag']=result_tag_list\n",
    "\n",
    "# output to greedy.out\n",
    "task3_output_list = test.values.tolist()\n",
    "first_flag = True\n",
    "with open('greedy.out', 'w') as f:\n",
    "    for each_output in task3_output_list:\n",
    "        index = each_output[0]\n",
    "        word_type = each_output[1]\n",
    "        tag = each_output[2]\n",
    "        if index==1:\n",
    "            if first_flag:\n",
    "                first_flag = False\n",
    "            else:\n",
    "                f.write('\\n')\n",
    "            \n",
    "        f.write(str(index)+'\\t'+word_type+'\\t'+tag)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the Viterbi algorithm predict sentence by sentence, so data is splited into list of sentences\n",
    "def get_sentences(i_list):\n",
    "    current_sentence = []\n",
    "    result = []\n",
    "    for each_pair in i_list:\n",
    "        if each_pair[0]!=1:\n",
    "            current_sentence.append(each_pair)\n",
    "        else:\n",
    "            result.append(current_sentence)\n",
    "            current_sentence = [each_pair]\n",
    "    result = result[1:]\n",
    "    result.append(current_sentence)\n",
    "    return result\n",
    "all_sentences = get_sentences(index_list)\n",
    "#all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Viterbi Algorithm ####\n",
    "viterbi_result_tag_list = []\n",
    "num_of_tags = len(all_tags)\n",
    "\n",
    "# for each sentence, compute tags for each word\n",
    "for each_sentence in all_sentences:\n",
    "\n",
    "    # initialize a Table to keep pai value, each cell contain (previous_tag,current_tag,max(transition*emission))\n",
    "    # for the first column, the previous_tag is '.'\n",
    "    pai = []\n",
    "    previous_tag=\".\"\n",
    "    each_row = each_sentence[0]\n",
    "    current_word = each_row[1]\n",
    "    \n",
    "    # if the word is not in word dictionary, we treat it as unknown\n",
    "    if current_word not in all_word:\n",
    "        # treat the word as '<unk_digit>' if the word start with a digit\n",
    "        if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "            current_word='<unk_digit>'\n",
    "        else:\n",
    "            current_word='<unk>'\n",
    "\n",
    "    # initialize first column of pai based on first word of sentence\n",
    "    current_col = []\n",
    "    # for each tag, compute (transition*emission), save to table pai\n",
    "    for each_tag in all_tags:\n",
    "        t_value = transition.get((previous_tag,each_tag),0)\n",
    "        e_value = emission.get((each_tag,current_word),0)\n",
    "        current_col.append((previous_tag,each_tag,t_value*e_value))\n",
    "    pai.append(current_col)\n",
    "\n",
    "\n",
    "    # compute other columns recursively\n",
    "    for i in range(1,len(each_sentence)):\n",
    "        each_row = each_sentence[i]\n",
    "        current_word = each_row[1]\n",
    "        # if the word is not in word dictionary, we treat it as unknown\n",
    "        if current_word not in all_word:\n",
    "            # treat the word as '<unk_digit>' if the word start with a digit\n",
    "            if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "                current_word='<unk_digit>'\n",
    "            else:\n",
    "                current_word='<unk>'\n",
    "\n",
    "                \n",
    "        previous_col = pai[i-1]\n",
    "        current_col = []\n",
    "        \n",
    "        # for each current tag, compute (transition*emission)for each previous tag and find argmax of it, \n",
    "        # then save (previous_tag,current_tag,max(pai*transition*emission) to table pai\n",
    "        for each_tag in all_tags:\n",
    "            test_max_list = []\n",
    "            for each_previous_pair in previous_col:\n",
    "                each_previous_tag = each_previous_pair[1] # get previous tag\n",
    "                each_previous_value = each_previous_pair[2]  # get previous pai value\n",
    "                t_value = transition.get((each_previous_tag,each_tag),0)\n",
    "                e_value = emission.get((each_tag,current_word),0)\n",
    "                test_max_list.append(t_value*e_value*each_previous_value)\n",
    "\n",
    "            # find argmax of (pai*transition*emission)\n",
    "            max_value = max(test_max_list)\n",
    "            max_index = test_max_list.index(max_value)\n",
    "            previous_tag = all_tags[max_index]\n",
    "            current_col.append((previous_tag,each_tag,max_value))\n",
    "        pai.append(current_col)\n",
    "\n",
    "\n",
    "\n",
    "    # traverse back\n",
    "    current_sentence_tag = []\n",
    "\n",
    "    # start from last column, find max pai value and its corresponding tag\n",
    "    current_col = pai[len(each_sentence)-1]\n",
    "    max_tup = max(current_col, key = lambda i : i[2])\n",
    "    current_sentence_tag.append(max_tup[1])\n",
    "\n",
    "    previous_tag = max_tup[0]\n",
    "    previous_index = all_tags.index(previous_tag)\n",
    "\n",
    "    # for other columns, recursively find max pai value and its corresponding tag\n",
    "    loop_list = list(range(len(each_sentence)-1))\n",
    "    loop_list.reverse()\n",
    "    for i in loop_list:\n",
    "        current_col = pai[i]\n",
    "        max_tup = current_col[previous_index]\n",
    "        current_sentence_tag.append(max_tup[1])\n",
    "        previous_tag = max_tup[0]\n",
    "        previous_index = all_tags.index(previous_tag)\n",
    "\n",
    "    # flip the tags since this is a traverse back process\n",
    "    current_sentence_tag.reverse()\n",
    "    \n",
    "    # save predict tags\n",
    "    viterbi_result_tag_list = viterbi_result_tag_list+current_sentence_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of applying Viterbi algorithm on dev data is 0.9494490316313521\n"
     ]
    }
   ],
   "source": [
    "# add predicted tag as a new column to compute accuracy\n",
    "dev['viterbi_tag']=viterbi_result_tag_list\n",
    "num_correct = dev[dev['correct_tag']==dev['viterbi_tag']].iloc[:,0].size\n",
    "print('The accuracy of applying Viterbi algorithm on dev data is '+str(num_correct/dev.iloc[:,0].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### predicting tags for test data ####\n",
    "# load test data\n",
    "test = pd.read_table('test',header=None, names=['index','word'])\n",
    "index_list_test = test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the Viterbi algorithm predict sentence by sentence, so data is splited into list of sentences\n",
    "def get_sentences(i_list):\n",
    "    current_sentence = []\n",
    "    result = []\n",
    "    for each_pair in i_list:\n",
    "        if each_pair[0]!=1:\n",
    "            current_sentence.append(each_pair)\n",
    "        else:\n",
    "            result.append(current_sentence)\n",
    "            current_sentence = [each_pair]\n",
    "    result = result[1:]\n",
    "    result.append(current_sentence)\n",
    "    return result\n",
    "all_sentences_test = get_sentences(index_list_test)\n",
    "#all_sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Viterbi Algorithm ####\n",
    "viterbi_result_tag_list = []\n",
    "num_of_tags = len(all_tags)\n",
    "\n",
    "# for each sentence, compute tags for each word\n",
    "for each_sentence in all_sentences_test:\n",
    "\n",
    "    # initialize a Table to keep pai value, each cell contain (previous_tag,current_tag,max(transition*emission))\n",
    "    # for the first column, the previous_tag is '.'\n",
    "    pai = []\n",
    "    previous_tag=\".\"\n",
    "    each_row = each_sentence[0]\n",
    "    current_word = each_row[1]\n",
    "    \n",
    "    # if the word is not in word dictionary, we treat it as unknown\n",
    "    if current_word not in all_word:\n",
    "        # treat the word as '<unk_digit>' if the word start with a digit\n",
    "        if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "            current_word='<unk_digit>'\n",
    "        else:\n",
    "            current_word='<unk>'\n",
    "\n",
    "    # initialize first column of pai based on first word of sentence\n",
    "    current_col = []\n",
    "    # for each tag, compute (transition*emission), save to table pai\n",
    "    for each_tag in all_tags:\n",
    "        t_value = transition.get((previous_tag,each_tag),0)\n",
    "        e_value = emission.get((each_tag,current_word),0)\n",
    "        current_col.append((previous_tag,each_tag,t_value*e_value))\n",
    "    pai.append(current_col)\n",
    "\n",
    "\n",
    "    # compute other columns recursively\n",
    "    for i in range(1,len(each_sentence)):\n",
    "        each_row = each_sentence[i]\n",
    "        current_word = each_row[1]\n",
    "        # if the word is not in word dictionary, we treat it as unknown\n",
    "        if current_word not in all_word:\n",
    "            # treat the word as '<unk_digit>' if the word start with a digit\n",
    "            if current_word[0]>= '0' and current_word[0] <= '9':\n",
    "                current_word='<unk_digit>'\n",
    "            else:\n",
    "                current_word='<unk>'\n",
    "\n",
    "                \n",
    "        previous_col = pai[i-1]\n",
    "        current_col = []\n",
    "        \n",
    "        # for each current tag, compute (transition*emission)for each previous tag and find argmax of it, \n",
    "        # then save (previous_tag,current_tag,max(pai*transition*emission) to table pai\n",
    "        for each_tag in all_tags:\n",
    "            test_max_list = []\n",
    "            for each_previous_pair in previous_col:\n",
    "                each_previous_tag = each_previous_pair[1] # get previous tag\n",
    "                each_previous_value = each_previous_pair[2]  # get previous pai value\n",
    "                t_value = transition.get((each_previous_tag,each_tag),0)\n",
    "                e_value = emission.get((each_tag,current_word),0)\n",
    "                test_max_list.append(t_value*e_value*each_previous_value)\n",
    "\n",
    "            # find argmax of (pai*transition*emission)\n",
    "            max_value = max(test_max_list)\n",
    "            max_index = test_max_list.index(max_value)\n",
    "            previous_tag = all_tags[max_index]\n",
    "            current_col.append((previous_tag,each_tag,max_value))\n",
    "        pai.append(current_col)\n",
    "\n",
    "\n",
    "\n",
    "    # traverse back\n",
    "    current_sentence_tag = []\n",
    "\n",
    "    # start from last column, find max pai value and its corresponding tag\n",
    "    current_col = pai[len(each_sentence)-1]\n",
    "    max_tup = max(current_col, key = lambda i : i[2])\n",
    "    current_sentence_tag.append(max_tup[1])\n",
    "\n",
    "    previous_tag = max_tup[0]\n",
    "    previous_index = all_tags.index(previous_tag)\n",
    "\n",
    "    # for other columns, recursively find max pai value and its corresponding tag\n",
    "    loop_list = list(range(len(each_sentence)-1))\n",
    "    loop_list.reverse()\n",
    "    for i in loop_list:\n",
    "        current_col = pai[i]\n",
    "        max_tup = current_col[previous_index]\n",
    "        current_sentence_tag.append(max_tup[1])\n",
    "        previous_tag = max_tup[0]\n",
    "        previous_index = all_tags.index(previous_tag)\n",
    "\n",
    "    # flip the tags since this is a traverse back process\n",
    "    current_sentence_tag.reverse()\n",
    "    \n",
    "    # save predict tags\n",
    "    viterbi_result_tag_list = viterbi_result_tag_list+current_sentence_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted tag as a new column and output it\n",
    "test['viterbi_tag']=viterbi_result_tag_list\n",
    "\n",
    "# output to viterbi.out\n",
    "task4_output_list = test.values.tolist()\n",
    "first_flag = True\n",
    "with open('viterbi.out', 'w') as f:\n",
    "    for each_output in task4_output_list:\n",
    "        index = each_output[0]\n",
    "        word_type = each_output[1]\n",
    "        tag = each_output[2]\n",
    "        if index==1:\n",
    "            if first_flag:\n",
    "                first_flag = False\n",
    "            else:\n",
    "                f.write('\\n')\n",
    "            \n",
    "        f.write(str(index)+'\\t'+word_type+'\\t'+tag)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
